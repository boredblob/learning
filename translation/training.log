Epoch 1 Batch 0 Loss 1.5245
Epoch 1 Batch 100 Loss 0.7897
Epoch 1 Batch 200 Loss 0.6827
Epoch 1 Batch 300 Loss 0.7400
Epoch 1 Batch 400 Loss 0.6693
Epoch 1 Batch 500 Loss 0.6390
Epoch 1 Batch 600 Loss 0.5097
Epoch 1 Batch 700 Loss 0.5803
Epoch 1 Batch 800 Loss 0.5765
Epoch 1 Batch 900 Loss 0.4756
Epoch 1 Batch 1000 Loss 0.5050
Epoch 1 Batch 1100 Loss 0.4818
Epoch 1 Batch 1200 Loss 0.4422
Epoch 1 Batch 1300 Loss 0.3974
Epoch 1 Batch 1400 Loss 0.4230
Epoch 1 Batch 1500 Loss 0.3342
Epoch 1 Batch 1600 Loss 0.3290
Epoch 1 Batch 1700 Loss 0.3842
Epoch 1 Batch 1800 Loss 0.3374
Epoch 1 Batch 1900 Loss 0.3266
Epoch 1 Batch 2000 Loss 0.3067
Epoch 1 Batch 2100 Loss 0.3355
Epoch 1 Batch 2200 Loss 0.3319
Epoch 1 Batch 2300 Loss 0.2731
Epoch 1 Loss 0.4733
Time taken for 1 epoch 2230.00 sec

Epoch 2 Batch 0 Loss 0.2460
Epoch 2 Batch 100 Loss 0.2034
Epoch 2 Batch 200 Loss 0.2329
Epoch 2 Batch 300 Loss 0.2692
Epoch 2 Batch 400 Loss 0.2621
Epoch 2 Batch 500 Loss 0.2824
Epoch 2 Batch 600 Loss 0.2469
Epoch 2 Batch 700 Loss 0.2273
Epoch 2 Batch 800 Loss 0.2053
Epoch 2 Batch 900 Loss 0.2243
Epoch 2 Batch 1000 Loss 0.2115
Epoch 2 Batch 1100 Loss 0.2134
Epoch 2 Batch 1200 Loss 0.2439
Epoch 2 Batch 1300 Loss 0.2203
Epoch 2 Batch 1400 Loss 0.2029
Epoch 2 Batch 1500 Loss 0.1602
Epoch 2 Batch 1600 Loss 0.1716
Epoch 2 Batch 1700 Loss 0.1517
Epoch 2 Batch 1800 Loss 0.1873
Epoch 2 Batch 1900 Loss 0.1603
Epoch 2 Batch 2000 Loss 0.1511
Epoch 2 Batch 2100 Loss 0.1992
Epoch 2 Batch 2200 Loss 0.1510
Epoch 2 Batch 2300 Loss 0.1542
Saved checkpoint for step 2: ./training_checkpoints
Epoch 2 Loss 0.2083
Time taken for 1 epoch 2171.54 sec

Epoch 3 Batch 0 Loss 0.1340
Epoch 3 Batch 100 Loss 0.1181
Epoch 3 Batch 200 Loss 0.1030
Epoch 3 Batch 300 Loss 0.1572
Epoch 3 Batch 400 Loss 0.1294
Epoch 3 Batch 500 Loss 0.1665
Epoch 3 Batch 600 Loss 0.1240
Epoch 3 Batch 700 Loss 0.1267
Epoch 3 Batch 800 Loss 0.1543
Epoch 3 Batch 900 Loss 0.1430
Epoch 3 Batch 1000 Loss 0.1217
Epoch 3 Batch 1100 Loss 0.1393
Epoch 3 Batch 1200 Loss 0.1619
Epoch 3 Batch 1300 Loss 0.1496
Epoch 3 Batch 1400 Loss 0.1242
Epoch 3 Batch 1500 Loss 0.1217
Epoch 3 Batch 1600 Loss 0.1529
Epoch 3 Batch 1700 Loss 0.1095
Epoch 3 Batch 1800 Loss 0.1197
Epoch 3 Batch 1900 Loss 0.1290
Epoch 3 Batch 2000 Loss 0.1522
Epoch 3 Batch 2100 Loss 0.1356
Epoch 3 Batch 2200 Loss 0.1145
Epoch 3 Batch 2300 Loss 0.1650
Epoch 3 Loss 0.1355
Time taken for 1 epoch 2144.65 sec

Epoch 4 Batch 0 Loss 0.0917
Epoch 4 Batch 100 Loss 0.0775
Epoch 4 Batch 200 Loss 0.1149
Epoch 4 Batch 300 Loss 0.0751
Epoch 4 Batch 400 Loss 0.0822
Epoch 4 Batch 500 Loss 0.1164
Epoch 4 Batch 600 Loss 0.1032
Epoch 4 Batch 700 Loss 0.0892
Epoch 4 Batch 800 Loss 0.1019
Epoch 4 Batch 900 Loss 0.0983
Epoch 4 Batch 1000 Loss 0.1097
Epoch 4 Batch 1100 Loss 0.1108
Epoch 4 Batch 1200 Loss 0.1669
Epoch 4 Batch 1300 Loss 0.0882
Epoch 4 Batch 1400 Loss 0.0942
Epoch 4 Batch 1500 Loss 0.1047
Epoch 4 Batch 1600 Loss 0.0789
Epoch 4 Batch 1700 Loss 0.1256
Epoch 4 Batch 1800 Loss 0.0775
Epoch 4 Batch 1900 Loss 0.1030
Epoch 4 Batch 2000 Loss 0.0791
Epoch 4 Batch 2100 Loss 0.1139
Epoch 4 Batch 2200 Loss 0.0819
Epoch 4 Batch 2300 Loss 0.0863
Saved checkpoint for step 4: ./training_checkpoints
Epoch 4 Loss 0.0995
Time taken for 1 epoch 2174.68 sec

Epoch 5 Batch 0 Loss 0.0558
Epoch 5 Batch 100 Loss 0.0465
Epoch 5 Batch 200 Loss 0.0708
Epoch 5 Batch 300 Loss 0.0599
Epoch 5 Batch 400 Loss 0.0861
Epoch 5 Batch 500 Loss 0.0589
Epoch 5 Batch 600 Loss 0.0683
Epoch 5 Batch 700 Loss 0.0700
Epoch 5 Batch 800 Loss 0.0822
Epoch 5 Batch 900 Loss 0.0632
Epoch 5 Batch 1000 Loss 0.0654
Epoch 5 Batch 1100 Loss 0.0667
Epoch 5 Batch 1200 Loss 0.0583
Epoch 5 Batch 1300 Loss 0.0602
Epoch 5 Batch 1400 Loss 0.0894
Epoch 5 Batch 1500 Loss 0.0896
Epoch 5 Batch 1600 Loss 0.0690
Epoch 5 Batch 1700 Loss 0.0967
Epoch 5 Batch 1800 Loss 0.1066
Epoch 5 Batch 1900 Loss 0.0915
Epoch 5 Batch 2000 Loss 0.0980
Epoch 5 Batch 2100 Loss 0.1006
Epoch 5 Batch 2200 Loss 0.0840
Epoch 5 Batch 2300 Loss 0.0930
Epoch 5 Loss 0.0757
Time taken for 1 epoch 2163.57 sec

Epoch 6 Batch 0 Loss 0.0617
Epoch 6 Batch 100 Loss 0.0365
Epoch 6 Batch 200 Loss 0.0588
Epoch 6 Batch 300 Loss 0.0427
Epoch 6 Batch 400 Loss 0.0616
Epoch 6 Batch 500 Loss 0.0654
Epoch 6 Batch 600 Loss 0.0483
Epoch 6 Batch 700 Loss 0.0607
Epoch 6 Batch 800 Loss 0.0529
Epoch 6 Batch 900 Loss 0.0442
Epoch 6 Batch 1000 Loss 0.0591
Epoch 6 Batch 1100 Loss 0.0564
Epoch 6 Batch 1200 Loss 0.0581
Epoch 6 Batch 1300 Loss 0.0652
Epoch 6 Batch 1400 Loss 0.0751
Epoch 6 Batch 1500 Loss 0.0531
Epoch 6 Batch 1600 Loss 0.0854
Epoch 6 Batch 1700 Loss 0.0659
Epoch 6 Batch 1800 Loss 0.0691
Epoch 6 Batch 1900 Loss 0.0623
Epoch 6 Batch 2000 Loss 0.0847
Epoch 6 Batch 2100 Loss 0.0736
Epoch 6 Batch 2200 Loss 0.0785
Epoch 6 Batch 2300 Loss 0.0861
Saved checkpoint for step 6: ./training_checkpoints
Epoch 6 Loss 0.0632
Time taken for 1 epoch 2176.70 sec

Epoch 7 Batch 0 Loss 0.0649
Epoch 7 Batch 100 Loss 0.0454
Epoch 7 Batch 200 Loss 0.0503
Epoch 7 Batch 300 Loss 0.0443
Epoch 7 Batch 400 Loss 0.0454
Epoch 7 Batch 500 Loss 0.0445
Epoch 7 Batch 600 Loss 0.0468
Epoch 7 Batch 700 Loss 0.0450
Epoch 7 Batch 800 Loss 0.0376
Epoch 7 Batch 900 Loss 0.0448
Epoch 7 Batch 1000 Loss 0.0399
Epoch 7 Batch 1100 Loss 0.0503
Epoch 7 Batch 1200 Loss 0.0441
Epoch 7 Batch 1300 Loss 0.0661
Epoch 7 Batch 1400 Loss 0.0404
Epoch 7 Batch 1500 Loss 0.0773
Epoch 7 Batch 1600 Loss 0.0508
Epoch 7 Batch 1700 Loss 0.0631
Epoch 7 Batch 1800 Loss 0.0475
Epoch 7 Batch 1900 Loss 0.0593
Epoch 7 Batch 2000 Loss 0.0602
Epoch 7 Batch 2100 Loss 0.0459
Epoch 7 Batch 2200 Loss 0.0691
Epoch 7 Batch 2300 Loss 0.0723
Epoch 7 Loss 0.0520
Time taken for 1 epoch 2162.42 sec

Epoch 8 Batch 0 Loss 0.0418
Epoch 8 Batch 100 Loss 0.0325
Epoch 8 Batch 200 Loss 0.0413
Epoch 8 Batch 300 Loss 0.0329
Epoch 8 Batch 400 Loss 0.0313
Epoch 8 Batch 500 Loss 0.0358
Epoch 8 Batch 600 Loss 0.0393
Epoch 8 Batch 700 Loss 0.0372
Epoch 8 Batch 800 Loss 0.0431
Epoch 8 Batch 900 Loss 0.0486
Epoch 8 Batch 1000 Loss 0.0503
Epoch 8 Batch 1100 Loss 0.0649
Epoch 8 Batch 1200 Loss 0.0680
Epoch 8 Batch 1300 Loss 0.0547
Epoch 8 Batch 1400 Loss 0.0492
Epoch 8 Batch 1500 Loss 0.0460
Epoch 8 Batch 1600 Loss 0.0481
Epoch 8 Batch 1700 Loss 0.0445
Epoch 8 Batch 1800 Loss 0.0521
Epoch 8 Batch 1900 Loss 0.0436
Epoch 8 Batch 2000 Loss 0.0392
Epoch 8 Batch 2100 Loss 0.0551
Epoch 8 Batch 2200 Loss 0.0550
Epoch 8 Batch 2300 Loss 0.0480
Saved checkpoint for step 8: ./training_checkpoints
Epoch 8 Loss 0.0479
Time taken for 1 epoch 2169.29 sec

Epoch 9 Batch 0 Loss 0.0392
Epoch 9 Batch 100 Loss 0.0358
Epoch 9 Batch 200 Loss 0.0438
Epoch 9 Batch 300 Loss 0.0309
Epoch 9 Batch 400 Loss 0.0163
Epoch 9 Batch 500 Loss 0.0291
Epoch 9 Batch 600 Loss 0.0238
Epoch 9 Batch 700 Loss 0.0239
Epoch 9 Batch 800 Loss 0.0477
Epoch 9 Batch 900 Loss 0.0338
Epoch 9 Batch 1000 Loss 0.0285
Epoch 9 Batch 1100 Loss 0.0382
Epoch 9 Batch 1200 Loss 0.0412
Epoch 9 Batch 1300 Loss 0.0359
Epoch 9 Batch 1400 Loss 0.0436
Epoch 9 Batch 1500 Loss 0.0391
Epoch 9 Batch 1600 Loss 0.0335
Epoch 9 Batch 1700 Loss 0.0429
Epoch 9 Batch 1800 Loss 0.0414
Epoch 9 Batch 1900 Loss 0.0490
Epoch 9 Batch 2000 Loss 0.0547
Epoch 9 Batch 2100 Loss 0.0403
Epoch 9 Batch 2200 Loss 0.0397
Epoch 9 Batch 2300 Loss 0.0598
Epoch 9 Loss 0.0402
Time taken for 1 epoch 2162.52 sec

Epoch 10 Batch 0 Loss 0.0340
Epoch 10 Batch 100 Loss 0.0327
Epoch 10 Batch 200 Loss 0.0268
Epoch 10 Batch 300 Loss 0.0258
Epoch 10 Batch 400 Loss 0.0347
Epoch 10 Batch 500 Loss 0.0236
Epoch 10 Batch 600 Loss 0.0375
Epoch 10 Batch 700 Loss 0.0235
Epoch 10 Batch 800 Loss 0.0369
Epoch 10 Batch 900 Loss 0.0299
Epoch 10 Batch 1000 Loss 0.0344
Epoch 10 Batch 1100 Loss 0.0307
Epoch 10 Batch 1200 Loss 0.0314
Epoch 10 Batch 1300 Loss 0.0399
Epoch 10 Batch 1400 Loss 0.0404
Epoch 10 Batch 1500 Loss 0.0333
Epoch 10 Batch 1600 Loss 0.0304
Epoch 10 Batch 1700 Loss 0.0358
Epoch 10 Batch 1800 Loss 0.0367
Epoch 10 Batch 1900 Loss 0.0296
Epoch 10 Batch 2000 Loss 0.0305
Epoch 10 Batch 2100 Loss 0.0464
Epoch 10 Batch 2200 Loss 0.0492
Epoch 10 Batch 2300 Loss 0.0436
Saved checkpoint for step 10: ./training_checkpoints
Epoch 10 Loss 0.0347
Time taken for 1 epoch 2171.26 sec

Epoch 11 Batch 0 Loss 0.0234
Epoch 11 Batch 100 Loss 0.0312
Epoch 11 Batch 200 Loss 0.0392
Epoch 11 Batch 300 Loss 0.0439
Epoch 11 Batch 400 Loss 0.0203
Epoch 11 Batch 500 Loss 0.0245
Epoch 11 Batch 600 Loss 0.0338
Epoch 11 Batch 700 Loss 0.0342
Epoch 11 Batch 800 Loss 0.0191
Epoch 11 Batch 900 Loss 0.0212
Epoch 11 Batch 1000 Loss 0.0356
Epoch 11 Batch 1100 Loss 0.0361
Epoch 11 Batch 1200 Loss 0.0364
Epoch 11 Batch 1300 Loss 0.0447
Epoch 11 Batch 1400 Loss 0.0258
Epoch 11 Batch 1500 Loss 0.0329
Epoch 11 Batch 1600 Loss 0.0409
Epoch 11 Batch 1700 Loss 0.0259
Epoch 11 Batch 1800 Loss 0.0289
Epoch 11 Batch 1900 Loss 0.0415
Epoch 11 Batch 2000 Loss 0.0245
Epoch 11 Batch 2100 Loss 0.0475
Epoch 11 Batch 2200 Loss 0.0313
Epoch 11 Batch 2300 Loss 0.0355
Epoch 11 Loss 0.0340
Time taken for 1 epoch 2161.77 sec

Epoch 12 Batch 0 Loss 0.0177
Epoch 12 Batch 100 Loss 0.0213
Epoch 12 Batch 200 Loss 0.0330
Epoch 12 Batch 300 Loss 0.0227
Epoch 12 Batch 400 Loss 0.0305
Epoch 12 Batch 500 Loss 0.0319
Epoch 12 Batch 600 Loss 0.0262
Epoch 12 Batch 700 Loss 0.0227
Epoch 12 Batch 800 Loss 0.0226
Epoch 12 Batch 900 Loss 0.0278
Epoch 12 Batch 1000 Loss 0.0349
Epoch 12 Batch 1100 Loss 0.0310
Epoch 12 Batch 1200 Loss 0.0246
Epoch 12 Batch 1300 Loss 0.0298
Epoch 12 Batch 1400 Loss 0.0358
Epoch 12 Batch 1500 Loss 0.0315
Epoch 12 Batch 1600 Loss 0.0364
Epoch 12 Batch 1700 Loss 0.0371
Epoch 12 Batch 1800 Loss 0.0229
Epoch 12 Batch 1900 Loss 0.0418
Epoch 12 Batch 2000 Loss 0.0308
Epoch 12 Batch 2100 Loss 0.0367
Epoch 12 Batch 2200 Loss 0.0620
Epoch 12 Batch 2300 Loss 0.0337
Saved checkpoint for step 12: ./training_checkpoints
Epoch 12 Loss 0.0297
Time taken for 1 epoch 2166.68 sec

Epoch 13 Batch 0 Loss 0.0283
Epoch 13 Batch 100 Loss 0.0104
Epoch 13 Batch 200 Loss 0.0193
Epoch 13 Batch 300 Loss 0.0275
Epoch 13 Batch 400 Loss 0.0313
Epoch 13 Batch 500 Loss 0.0283
Epoch 13 Batch 600 Loss 0.0300
Epoch 13 Batch 700 Loss 0.0257
Epoch 13 Batch 800 Loss 0.0263
Epoch 13 Batch 900 Loss 0.0294
Epoch 13 Batch 1000 Loss 0.0254
Epoch 13 Batch 1100 Loss 0.0325
Epoch 13 Batch 1200 Loss 0.0265
Epoch 13 Batch 1300 Loss 0.0264
Epoch 13 Batch 1400 Loss 0.0340
Epoch 13 Batch 1500 Loss 0.0291
Epoch 13 Batch 1600 Loss 0.0383
Epoch 13 Batch 1700 Loss 0.0322
Epoch 13 Batch 1800 Loss 0.0224
Epoch 13 Batch 1900 Loss 0.0246
Epoch 13 Batch 2000 Loss 0.0434
Epoch 13 Batch 2100 Loss 0.0450
Epoch 13 Batch 2200 Loss 0.0332
Epoch 13 Batch 2300 Loss 0.0474
Epoch 13 Loss 0.0289
Time taken for 1 epoch 2159.37 sec

Epoch 14 Batch 0 Loss 0.0245
Epoch 14 Batch 100 Loss 0.0245
Epoch 14 Batch 200 Loss 0.0169
Epoch 14 Batch 300 Loss 0.0180
Epoch 14 Batch 400 Loss 0.0227
Epoch 14 Batch 500 Loss 0.0286
Epoch 14 Batch 600 Loss 0.0269
Epoch 14 Batch 700 Loss 0.0309
Epoch 14 Batch 800 Loss 0.0262
Epoch 14 Batch 900 Loss 0.0278
Epoch 14 Batch 1000 Loss 0.0180
Epoch 14 Batch 1100 Loss 0.0250
Epoch 14 Batch 1200 Loss 0.0343
Epoch 14 Batch 1300 Loss 0.0395
Epoch 14 Batch 1400 Loss 0.0267
Epoch 14 Batch 1500 Loss 0.0361
Epoch 14 Batch 1600 Loss 0.0200
Epoch 14 Batch 1700 Loss 0.0481
Epoch 14 Batch 1800 Loss 0.0243
Epoch 14 Batch 1900 Loss 0.0273
Epoch 14 Batch 2000 Loss 0.0216
Epoch 14 Batch 2100 Loss 0.0353
Epoch 14 Batch 2200 Loss 0.0328
Epoch 14 Batch 2300 Loss 0.0317
Saved checkpoint for step 14: ./training_checkpoints
Epoch 14 Loss 0.0275
Time taken for 1 epoch 2171.85 sec

Epoch 15 Batch 0 Loss 0.0113
Epoch 15 Batch 100 Loss 0.0208
Epoch 15 Batch 200 Loss 0.0165
Epoch 15 Batch 300 Loss 0.0169
Epoch 15 Batch 400 Loss 0.0238
Epoch 15 Batch 500 Loss 0.0234
Epoch 15 Batch 600 Loss 0.0245
Epoch 15 Batch 700 Loss 0.0343
Epoch 15 Batch 800 Loss 0.0293
Epoch 15 Batch 900 Loss 0.0307
Epoch 15 Batch 1000 Loss 0.0196
Epoch 15 Batch 1100 Loss 0.0358
Epoch 15 Batch 1200 Loss 0.0216
Epoch 15 Batch 1300 Loss 0.0211
Epoch 15 Batch 1400 Loss 0.0225
Epoch 15 Batch 1500 Loss 0.0183
Epoch 15 Batch 1600 Loss 0.0315
Epoch 15 Batch 1700 Loss 0.0427
Epoch 15 Batch 1800 Loss 0.0327
Epoch 15 Batch 1900 Loss 0.0351
Epoch 15 Batch 2000 Loss 0.0238
Epoch 15 Batch 2100 Loss 0.0309
Epoch 15 Batch 2200 Loss 0.0241
Epoch 15 Batch 2300 Loss 0.0224
Epoch 15 Loss 0.0256
Time taken for 1 epoch 2159.84 sec

Epoch 16 Batch 0 Loss 0.0226
Epoch 16 Batch 100 Loss 0.0217
Epoch 16 Batch 200 Loss 0.0198
Epoch 16 Batch 300 Loss 0.0149
Epoch 16 Batch 400 Loss 0.0183
Epoch 16 Batch 500 Loss 0.0256
Epoch 16 Batch 600 Loss 0.0191
Epoch 16 Batch 700 Loss 0.0165
Epoch 16 Batch 800 Loss 0.0155
Epoch 16 Batch 900 Loss 0.0190
Epoch 16 Batch 1000 Loss 0.0283
Epoch 16 Batch 1100 Loss 0.0239
Epoch 16 Batch 1200 Loss 0.0247
Epoch 16 Batch 1300 Loss 0.0186
Epoch 16 Batch 1400 Loss 0.0275
Epoch 16 Batch 1500 Loss 0.0278
Epoch 16 Batch 1600 Loss 0.0434
Epoch 16 Batch 1700 Loss 0.0195
Epoch 16 Batch 1800 Loss 0.0381
Epoch 16 Batch 1900 Loss 0.0349
Epoch 16 Batch 2000 Loss 0.0335
Epoch 16 Batch 2100 Loss 0.0266
Epoch 16 Batch 2200 Loss 0.0352
Epoch 16 Batch 2300 Loss 0.0297
Saved checkpoint for step 16: ./training_checkpoints
Epoch 16 Loss 0.0255
Time taken for 1 epoch 2167.76 sec

Epoch 17 Batch 0 Loss 0.0209
Epoch 17 Batch 100 Loss 0.0158
Epoch 17 Batch 200 Loss 0.0166
Epoch 17 Batch 300 Loss 0.0204
Epoch 17 Batch 400 Loss 0.0312
Epoch 17 Batch 500 Loss 0.0219
Epoch 17 Batch 600 Loss 0.0189
Epoch 17 Batch 700 Loss 0.0275
Epoch 17 Batch 800 Loss 0.0231
Epoch 17 Batch 900 Loss 0.0190
Epoch 17 Batch 1000 Loss 0.0221
Epoch 17 Batch 1100 Loss 0.0225
Epoch 17 Batch 1200 Loss 0.0282
Epoch 17 Batch 1300 Loss 0.0234
Epoch 17 Batch 1400 Loss 0.0330
Epoch 17 Batch 1500 Loss 0.0246
Epoch 17 Batch 1600 Loss 0.0214
Epoch 17 Batch 1700 Loss 0.0354
Epoch 17 Batch 1800 Loss 0.0191
Epoch 17 Batch 1900 Loss 0.0215
Epoch 17 Batch 2000 Loss 0.0495
Epoch 17 Batch 2100 Loss 0.0208
Epoch 17 Batch 2200 Loss 0.0321
Epoch 17 Batch 2300 Loss 0.0207
Epoch 17 Loss 0.0242
Time taken for 1 epoch 2163.11 sec

Epoch 18 Batch 0 Loss 0.0169
Epoch 18 Batch 100 Loss 0.0240
Epoch 18 Batch 200 Loss 0.0197
Epoch 18 Batch 300 Loss 0.0182
Epoch 18 Batch 400 Loss 0.0259
Epoch 18 Batch 500 Loss 0.0144
Epoch 18 Batch 600 Loss 0.0223
Epoch 18 Batch 700 Loss 0.0273
Epoch 18 Batch 800 Loss 0.0227
Epoch 18 Batch 900 Loss 0.0180
Epoch 18 Batch 1000 Loss 0.0229
Epoch 18 Batch 1100 Loss 0.0192
Epoch 18 Batch 1200 Loss 0.0299
Epoch 18 Batch 1300 Loss 0.0295
Epoch 18 Batch 1400 Loss 0.0286
Epoch 18 Batch 1500 Loss 0.0205
Epoch 18 Batch 1600 Loss 0.0295
Epoch 18 Batch 1700 Loss 0.0217
Epoch 18 Batch 1800 Loss 0.0364
Epoch 18 Batch 1900 Loss 0.0278
Epoch 18 Batch 2000 Loss 0.0271
Epoch 18 Batch 2100 Loss 0.0308
Epoch 18 Batch 2200 Loss 0.0322
Epoch 18 Batch 2300 Loss 0.0313
Saved checkpoint for step 18: ./training_checkpoints
Epoch 18 Loss 0.0250
Time taken for 1 epoch 2168.64 sec

Epoch 19 Batch 0 Loss 0.0156
Epoch 19 Batch 100 Loss 0.0140
Epoch 19 Batch 200 Loss 0.0251
Epoch 19 Batch 300 Loss 0.0301
Epoch 19 Batch 400 Loss 0.0236
Epoch 19 Batch 500 Loss 0.0202
Epoch 19 Batch 600 Loss 0.0184
Epoch 19 Batch 700 Loss 0.0249
Epoch 19 Batch 800 Loss 0.0245
Epoch 19 Batch 900 Loss 0.0196
Epoch 19 Batch 1000 Loss 0.0409
Epoch 19 Batch 1100 Loss 0.0308
Epoch 19 Batch 1200 Loss 0.0311
Epoch 19 Batch 1300 Loss 0.0225
Epoch 19 Batch 1400 Loss 0.0200
Epoch 19 Batch 1500 Loss 0.0304
Epoch 19 Batch 1600 Loss 0.0249
Epoch 19 Batch 1700 Loss 0.0232
Epoch 19 Batch 1800 Loss 0.0130
Epoch 19 Batch 1900 Loss 0.0328
Epoch 19 Batch 2000 Loss 0.0238
Epoch 19 Batch 2100 Loss 0.0256
Epoch 19 Batch 2200 Loss 0.0253
Epoch 19 Batch 2300 Loss 0.0293
Epoch 19 Loss 0.0244
Time taken for 1 epoch 2163.46 sec

Epoch 20 Batch 0 Loss 0.0175
Epoch 20 Batch 100 Loss 0.0160
Epoch 20 Batch 200 Loss 0.0199
Epoch 20 Batch 300 Loss 0.0147
Epoch 20 Batch 400 Loss 0.0228
Epoch 20 Batch 500 Loss 0.0157
Epoch 20 Batch 600 Loss 0.0207
Epoch 20 Batch 700 Loss 0.0241
Epoch 20 Batch 800 Loss 0.0177
Epoch 20 Batch 900 Loss 0.0203
Epoch 20 Batch 1000 Loss 0.0161
Epoch 20 Batch 1100 Loss 0.0199
Epoch 20 Batch 1200 Loss 0.0257
Epoch 20 Batch 1300 Loss 0.0244
Epoch 20 Batch 1400 Loss 0.0186
Epoch 20 Batch 1500 Loss 0.0210
Epoch 20 Batch 1600 Loss 0.0301
Epoch 20 Batch 1700 Loss 0.0254
Epoch 20 Batch 1800 Loss 0.0257
Epoch 20 Batch 1900 Loss 0.0192
Epoch 20 Batch 2000 Loss 0.0270
Epoch 20 Batch 2100 Loss 0.0322
Epoch 20 Batch 2200 Loss 0.0195
Epoch 20 Batch 2300 Loss 0.0274
Saved checkpoint for step 20: ./training_checkpoints
Epoch 20 Loss 0.0219
Time taken for 1 epoch 2167.47 sec



Traceback (most recent call last):
  File "training.py", line 228, in <module>
    encoder.save('./encoder.h5')
  File "C:\Program Files\Python38\lib\site-packages\tensorflow\python\keras\engine\training.py", line 2001, in save
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
  File "C:\Program Files\Python38\lib\site-packages\tensorflow\python\keras\saving\save.py", line 146, in save_model
    raise NotImplementedError(
NotImplementedError: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format="tf") or using `save_weights`.